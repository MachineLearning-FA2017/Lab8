{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strating with a Simple Example: Digits Data from sklearn\n",
    "Let's start our adventure into convolutional networks with a simple example of the digits dataset. This was not always such a simple example, but modern day computing power and open source tools has made it a significantly more tractable problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import datasets as ds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, os.path\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "import matplotlib.pyplot as plt\n",
    "import colorsys\n",
    "import copy\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.decomposition import KernelPCA\n",
    "import zipfile\n",
    "\n",
    "import skimage\n",
    "from skimage import io\n",
    "\n",
    "from skimage.transform import resize\n",
    "from random import shuffle\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "# define X and y here.\n",
    "import glob2\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_data = []\n",
    "image_labels = []\n",
    "\n",
    "directory = \"./train\"\n",
    "os.walk(directory)\n",
    "folder_names = [x[0] for x in os.walk(directory)]\n",
    "del folder_names[0]\n",
    "print(folder_names)\n",
    "categories = {category.replace('./train\\\\', '') for category in folder_names}\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time\n",
    "fish_image_files = glob2.glob('train/**/*.jpg')\n",
    "size = 300, 300\n",
    "# Also need to get labels from the filename and associate with each image. Just a parallele numpy array with target classes would be good.\n",
    "\n",
    "# for folder in train\n",
    "# folder is the y\n",
    "# for file in folder\n",
    "# file is the x\n",
    "igs = np.array([skimage.transform.resize(skimage.io.imread(fname, as_grey=True, plugin=None, flatten=None),(300,300))\n",
    "                                         for fname in fish_image_files])\n",
    "# Print variable fname and see if the string contains path which indicates the target function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "max = 50\n",
    "i = 0\n",
    "flag = False\n",
    "for sub in os.listdir(“./train”):\n",
    "    if(sub == ‘.DS_Store’):\n",
    "        continue\n",
    "    for file in os.listdir(“./train/“+sub):\n",
    "        shutil.copy2(“./train/“+ sub + “/”+ file,‘./train2’)\n",
    "        i += 1\n",
    "        if(i == max):\n",
    "            flag = True\n",
    "            break\n",
    "    if(flag == True):\n",
    "        i = 0\n",
    "fish_image_files = glob2.glob(‘train2/*.jpg’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_labels = []\n",
    "for fname in fish_image_files:\n",
    "    image_labels.append(re.sub('/img.*', '', fname.replace('train/', '')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    plt.imshow(igs[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_data = igs.astype('float32')\n",
    "#train_data = train_data / 255\n",
    "#igs_pca = train_data.reshape(igs.shape[0], (train_data.shape[1]*train_data.shape[2]))\n",
    "X = igs\n",
    "y = np.asarray(image_labels)\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split it into train / test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Split X_train again to create validation data\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=0.2)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What do these images look like?\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# a helper plotting function\n",
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=6):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.7 * n_col, 2.3 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i], cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "plot_gallery(X_train, y_train, 8, 8) # defaults to showing a 3 by 6 subset of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A reminder of what convolution is\n",
    "from skimage.io import imshow\n",
    "from skimage.filters import sobel_h, sobel_v\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "\n",
    "idx_to_reconstruct = int(np.random.rand(1)*len(X))\n",
    "img  = X[idx_to_reconstruct]\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "imshow(img,cmap='bone')\n",
    "\n",
    "sv = sobel_v(img)\n",
    "sh = sobel_h(img)\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "imshow(sv,cmap='bone')\n",
    "plt.subplot(1,4,3)\n",
    "imshow(sh,cmap='bone')\n",
    "\n",
    "gradient_mag = np.sqrt(sv**2 + sh**2 ) \n",
    "plt.subplot(1,4,4)\n",
    "imshow(gradient_mag,cmap='bone')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows two separate convolutions of one digit using sobel filters (essentially vertical and horizontal edge detectors, derivative). The far image is the combined magnitudes of the sobel filters. Wouldn't it be great if we did not need to specify the correct filters? What if we could just let the weights of the convolution be found through neural netowrk training methods. \n",
    "\n",
    "Of course, we can. Let's do one example with a simple CNN architecture and compare it to the performance of a pixel wise MLP.\n",
    "\n",
    "____\n",
    "# A very Simple ConvNet Versus a Raw Pixel Input MLP\n",
    "In general, the flattened images placed through a MLP can be quite accurate (as we have seen in the past). Even so, using convolitional filters and pooling should provide us with some better resilience to small perturbations in the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 8\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train = X_train.reshape(3021, 90000)\n",
    "X_test = X_test.reshape(756, 90000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "y_train = y_train[0]\n",
    "y_test = y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "#y_train_ohe = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "#y_test_ohe = keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "y_train_ohe = y_train\n",
    "y_test_ohe = y_test\n",
    "\n",
    "# make a 3 layer keras MLP\n",
    "mlp = Sequential()\n",
    "mlp.add( Dense(input_dim=X_train.shape[1], units=30, activation='relu') )\n",
    "mlp.add( Dense(units=15, activation='relu') )\n",
    "mlp.add( Dense(NUM_CLASSES) )\n",
    "mlp.add( Activation('softmax') )\n",
    "\n",
    "mlp.compile(loss='mean_squared_error',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "mlp.fit(X_train, y_train_ohe, \n",
    "        batch_size=32, epochs=150, \n",
    "        shuffle=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# make a CNN with conv layer and max pooling\n",
    "cnn = Sequential()\n",
    "cnn.add(Reshape((1,8,8), input_shape=(1,64)))\n",
    "cnn.add(Conv2D(filters=16, kernel_size= (2, 2), padding='same', input_shape=(1,8,8)))\n",
    "cnn.add(Activation('relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "# add one layer on flattened output\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(NUM_CLASSES))\n",
    "cnn.add(Activation('softmax'))\n",
    "\n",
    "# Let's train the model \n",
    "cnn.compile(loss='mean_squared_error',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# we need to exapnd the dimensions here to give the \n",
    "#   \"channels\" dimension expected by Keras\n",
    "cnn.fit(np.expand_dims(X_train, axis=1), y_train_ohe, \n",
    "        batch_size=32, epochs=150, \n",
    "        shuffle=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "def compare_mlp_cnn(cnn, mlp, X_test, y_test):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    if cnn is not None:\n",
    "        yhat_cnn = np.argmax(cnn.predict(np.expand_dims(X_test, axis=1)), axis=1)\n",
    "        acc_cnn = mt.accuracy_score(y_test,yhat_cnn)\n",
    "        plt.subplot(1,2,1)\n",
    "        cm = mt.confusion_matrix(y_test,yhat_cnn)\n",
    "        cm = cm/np.sum(cm,axis=1)[:,np.newaxis]\n",
    "        sns.heatmap(cm, annot=True, fmt='.2f')\n",
    "        plt.title('CNN: '+str(acc_cnn))\n",
    "    \n",
    "    if mlp is not None:\n",
    "        yhat_mlp = np.argmax(mlp.predict(X_test), axis=1)\n",
    "        acc_mlp = mt.accuracy_score(y_test,yhat_mlp)\n",
    "        plt.subplot(1,2,2)\n",
    "        cm = mt.confusion_matrix(y_test,yhat_mlp)\n",
    "        cm = cm/np.sum(cm,axis=1)[:,np.newaxis]\n",
    "        sns.heatmap(cm,annot=True, fmt='.2f')\n",
    "        plt.title('MLP: '+str(acc_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_mlp_cnn(cnn,mlp,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# changes: \n",
    "#    1. increased kernel size\n",
    "cnn2 = Sequential()\n",
    "cnn2.add(Reshape((1,8,8), input_shape=(1,64)))\n",
    "cnn2.add(Conv2D(filters=16, kernel_size= (3, 3), padding='same', input_shape=(1,8,8)))\n",
    "cnn2.add(Activation('relu'))\n",
    "cnn2.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "# add one layer on flattened output\n",
    "cnn2.add(Flatten())\n",
    "cnn2.add(Dense(NUM_CLASSES))\n",
    "cnn2.add(Activation('softmax'))\n",
    "\n",
    "# Let's train the model \n",
    "cnn2.compile(loss='mean_squared_error',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# we need to exapnd the dimensions here to give the \n",
    "#   \"channels\" dimension expected by Keras\n",
    "cnn2.fit(np.expand_dims(X_train, axis=1), y_train_ohe, \n",
    "        batch_size=32, epochs=150, \n",
    "        shuffle=True, verbose=0)\n",
    "\n",
    "compare_mlp_cnn(cnn2,mlp,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# changes: \n",
    "#    1. increased kernel size\n",
    "#    2. add another conv/pool layer \n",
    "cnn3 = Sequential()\n",
    "cnn3.add(Reshape((1,8,8), input_shape=(1,64)))\n",
    "\n",
    "num_filt_layers = [32, 32]\n",
    "for num_filters in num_filt_layers:\n",
    "    cnn3.add(Conv2D(filters=num_filters, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding='same'))\n",
    "    cnn3.add(Activation('relu'))\n",
    "    cnn3.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    \n",
    "\n",
    "# add one layer on flattened output\n",
    "cnn3.add(Flatten())\n",
    "cnn3.add(Dense(NUM_CLASSES))\n",
    "cnn3.add(Activation('softmax'))\n",
    "\n",
    "# Let's train the model \n",
    "cnn3.compile(loss='mean_squared_error',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# we need to exapnd the dimensions here to give the \n",
    "#   \"channels\" dimension expected by Keras\n",
    "cnn3.fit(np.expand_dims(X_train, axis=1), y_train_ohe, \n",
    "        batch_size=32, epochs=150, \n",
    "        shuffle=True, verbose=0)\n",
    "\n",
    "compare_mlp_cnn(cnn3,mlp,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# changes: \n",
    "#    1. increased kernel size\n",
    "#    2. add another conv/pool layer with increasing num filters\n",
    "#    3. add more layers once flattened\n",
    "cnn4 = Sequential()\n",
    "cnn4.add(Reshape((1,8,8), input_shape=(1,64)))\n",
    "\n",
    "num_filt_layers = [24, 48]\n",
    "for num_filters in num_filt_layers:\n",
    "    cnn4.add(Conv2D(filters=num_filters, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding='same'))\n",
    "    cnn4.add(Activation('relu'))\n",
    "    cnn4.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    \n",
    "\n",
    "# add one layer on flattened output\n",
    "cnn4.add(Flatten())\n",
    "cnn4.add(Dense(100))\n",
    "cnn4.add(Activation('relu'))\n",
    "cnn4.add(Dense(NUM_CLASSES))\n",
    "cnn4.add(Activation('softmax'))\n",
    "\n",
    "# Let's train the model \n",
    "cnn4.compile(loss='mean_squared_error',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# we need to exapnd the dimensions here to give the \n",
    "#   \"channels\" dimension expected by Keras\n",
    "cnn4.fit(np.expand_dims(X_train, axis=1), y_train_ohe, \n",
    "        batch_size=64, epochs=100, \n",
    "        shuffle=True, verbose=0)\n",
    "\n",
    "compare_mlp_cnn(cnn4,mlp,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "Okay, so we are honing in on the best performance for the digits data. But, we really need something a bit bigger to work on. Enter: MNIST. We have already used this dataset in the past, where we got about 97% accuracy with our custom MLP. Lets see how well Keras and tensorflow can perform!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# more data for handwriting recognition?\n",
    "# Let's use Raschka's implementation for using the mnist dataset:\n",
    "# https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch12/ch12.ipynb\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "# from sklearn.preprocessing import RobustScaler\n",
    "NUM_CLASSES = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "y_train_ohe = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_ohe = keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "# make a keras MLP\n",
    "mlp = Sequential()\n",
    "mlp.add( Dense(input_dim=X_train.shape[1], units=100, activation='relu') )\n",
    "mlp.add( Dense(units=50, activation='relu') )\n",
    "mlp.add( Dense(units=50, activation='relu') )\n",
    "mlp.add( Dense(NUM_CLASSES) )\n",
    "mlp.add( Activation('softmax') )\n",
    "\n",
    "mlp.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "mlp.fit(X_train, y_train_ohe, \n",
    "        batch_size=32, epochs=15, \n",
    "        shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_mlp_cnn(None,mlp,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "img_wh = 28 # width and height of MNIST images\n",
    "\n",
    "# changes: \n",
    "#    1. Baseline: 2 conv layers and two output layers\n",
    "cnn1 = Sequential()\n",
    "cnn1.add(Reshape((1,img_wh, img_wh), input_shape=(1,img_wh**2)))\n",
    "\n",
    "num_filt_layers = [24, 24]\n",
    "for num_filters in num_filt_layers:\n",
    "    cnn1.add(Conv2D(filters=num_filters, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding='same'))\n",
    "    cnn1.add(Activation('relu'))\n",
    "    cnn1.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    \n",
    "\n",
    "# add one layer on flattened output\n",
    "cnn1.add(Flatten())\n",
    "cnn1.add(Dense(100, activation='relu'))\n",
    "cnn1.add(Dense(100, activation='relu'))\n",
    "cnn1.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "# Let's train the model \n",
    "cnn1.compile(loss='mean_squared_error',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# we need to exapnd the dimensions here to give the \n",
    "#   \"channels\" dimension expected by Keras\n",
    "cnn1.fit(np.expand_dims(X_train, axis=1), y_train_ohe, \n",
    "        batch_size=32, epochs=15, \n",
    "        shuffle=True, verbose=1)\n",
    "\n",
    "compare_mlp_cnn(cnn1,mlp,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Copy TensorFlow Architecture from \n",
    "#   Deep MNIST for experts\n",
    "#   https://www.tensorflow.org/versions/r0.11/tutorials/mnist/pros/index.html\n",
    "\n",
    "# Manipulated to mirror parts of this network:\n",
    "#   http://ankivil.com/mnist-database-and-simple-classification-networks/\n",
    "\n",
    "cnn2 = Sequential()\n",
    "cnn2.add(Reshape((1,img_wh, img_wh), input_shape=(1,img_wh**2)))\n",
    "\n",
    "num_filt_layers = [32, 64]\n",
    "for num_filters in num_filt_layers:\n",
    "    cnn2.add(Conv2D(filters=num_filters, \n",
    "                    kernel_size=(3,3), \n",
    "                    padding='same', \n",
    "                    activation='relu')) # more compact syntax\n",
    "\n",
    "    # max pooling\n",
    "    cnn2.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "    \n",
    "\n",
    "# add one layer on flattened output\n",
    "cnn2.add(Dropout(0.25)) # add some dropout for regularization after conv layers\n",
    "cnn2.add(Flatten())\n",
    "cnn2.add(Dense(1024, activation='relu'))\n",
    "cnn2.add(Dropout(0.5)) # add some dropout for regularization, again!\n",
    "cnn2.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "# Let's train the model \n",
    "cnn2.compile(loss='categorical_crossentropy', # 'categorical_crossentropy' 'mean_squared_error'\n",
    "              optimizer='rmsprop', # 'adadelta' 'rmsprop'\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# we need to exapnd the dimensions here to give the \n",
    "#   \"channels\" dimension expected by Keras\n",
    "cnn2.fit(np.expand_dims(X_train, axis=1), y_train_ohe, \n",
    "        batch_size=128, epochs=11, \n",
    "        shuffle=True, verbose=1,\n",
    "        validation_data=(np.expand_dims(X_test, axis=1),y_test_ohe))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_mlp_cnn(cnn2,mlp,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnn2.evaluate(np.expand_dims(X_test, axis=1),y_test_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# want to save this model for later?\n",
    "cnn2.save('large_data/mnist_cnn.h5')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
